# -*- coding: utf-8 -*-
"""
Created on Sun Apr 21 23:15:17 2024

@author: 李魚
"""

import numpy as np

import matplotlib.pyplot as plt
from tensorflow.keras.preprocessing import sequence

from keras.models import Sequential
from keras.layers import Dense, Dropout, Activation,Flatten
from keras.layers import Embedding
from keras.layers import LSTM
from tensorflow.keras.preprocessing.text import Tokenizer

import jieba

#取得停用詞
import os

def load_stopwords():
    # 取得當前執行檔案的絕對路徑
    current_path = os.path.abspath(__file__)
    
    # 獲取所在目錄的路徑
    directory = os.path.dirname(current_path)
    
    # 構建 'wordstop.txt' 檔案的完整路徑
    wordstop_path = os.path.join(directory, 'wordstop.txt')
    
    # 打開 'wordstop.txt' 檔案並讀取停用詞
    with open(wordstop_path, 'r', encoding='utf8') as f:
        stopWords = f.read().split('\n')
        
    stopWords.append('\n')
    
    return stopWords

# 調用函式加載停用詞
stopWords = load_stopwords()


#讓資料load進來
x_train = np.array(['這款調酒的口感非常豐富，讓人回味無窮。', '配料搭配的完美', '真有趣', '這一杯調酒真好喝', '它的口感清新宜人，令人回味無窮', '這杯調酒的香氣宜人迷人', '這杯調酒的味道濃郁香甜，美味無比','它的甜度過高，讓人感到膩口', '這杯調酒的氣泡太少，缺乏活力', '它的風味有點混亂，讓人感到困惑', '這杯調酒的味道有些單調，缺乏層次感', '它的酒味太過澀苦，令人難以接受', '它的風味過於平淡，缺乏令人印象深刻的特色', '這杯調酒的酸度不夠平衡，缺乏整體的和諧感', '它的口感有點生硬，缺乏柔順的感覺'])
y_train = np.array([1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0])

#把標籤設定成固定格式[0,1](這樣是1)，[1,0](這樣是0)
from tensorflow.python.keras.utils import np_utils
y_train = np_utils.to_categorical(y_train, 2)

sentence=[]

#透過jieba分詞工具，把自分成一個一個單字
for content in x_train:
    _sentence=list(jieba.cut(content, cut_all=True))
    sentence.append(_sentence)

remainderWords2 = []

#如果裡面有停用詞，將其移除
for content in sentence:
    remainderWords2.append(list(filter(lambda a: a not in stopWords, content)))

#建立中文字典，把文字轉換成數字(取最常使用到的3000個字)
token = Tokenizer(num_words=3000)
token.fit_on_texts(remainderWords2)

x_train_seq = token.texts_to_sequences(remainderWords2)#把資料轉換成為數字

x_train = sequence.pad_sequences(x_train_seq, maxlen=50)#把每一筆資料轉換長度為50
print(x_train.shape)

model = Sequential()
# 将字典长度改为3000，评论数据长度改为50
model.add(Embedding(output_dim=128,
                    input_dim=3000,  # 修改为3000
                    input_length=50))

model.add(LSTM(units=64))  # 删除activation参数

model.add(Dropout(0.5))

model.add(Dense(units=256,
                activation='relu'))
model.add(Dropout(0.5))  # Dropout值改为0.5

model.add(Dense(units=2,
                activation='sigmoid'))
model.summary()

model.compile(loss='binary_crossentropy', 
              optimizer='adam', 
              metrics=['accuracy'])

train_history =model.fit(x_train, 
                         y_train,
                         batch_size=100, 
                         epochs=10,
                         verbose=2,
                         validation_split=0.2)

x_test =x_train[:1]

# 使用模型进行预测
predictions = model.predict(x_test)

print(np.argmax(predictions,axis=1))
